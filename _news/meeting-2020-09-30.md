---
layout: post
title: Lab meeting - Maya Watt
date: 2020-09-30
published: true
inline: false 
---

At this week's lab meeting, [**Maya Watt**](/people/watt.maya) will be presenting her research on the rates of over-irregularization of English past-tense verbs. 

- **Wednesday, September 30th**, at **13:30 UTC-4**
- Meetings are via Zoom. If you would like to attend and have not already signed up for the MCQLL mailing list, please fill out [this google form](https://forms.gle/fBu5eYfiF2Ctnv5e7).

#### Abstract 

<blockquote>
	In her talk, Maya will discuss the rates of over-irregularization of English past-tense verbs (i.e. believing the past tense of snow is snew instead of snowed). Such mistakes rarely happen in natural speech, so very little is know about the nuances of over-irregularization — do people tend to over-irregularize verbs of a particular inflectional class, or do the rates stay fairly similar? Because capturing an instance of over-irregularization in natural speech is difficult, we decided to collect our data via implementing a lexical decision task (LDT) and launching it on Mechanical Turk. The assumption is that highly natural over-irregularized non-words (e.g. brang) will take longer to be judged as non-words than other, less-natural non-words (e.g. screamt). The goal of this project is to provide some data and insight into language learning and productive morphology.
</blockquote>

#### Bio
Maya is an undergraduate student in Linguistics and Computer Science. She’s interested in syntax, logic, and formal linguistics. Her research interests lie in the intersection of natural language and mathematics.