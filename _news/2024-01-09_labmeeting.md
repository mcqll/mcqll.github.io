---
layout: post
title: Lab meeting - Eva Portelance
date: 2024-01-09
published: true
inline: false
---

At this semester's first MCQLL meeting, [**Eva Portelance**](/people/portelance.eva) will
be presenting **The roles of neural networks in language acquisition**.

> __When:__ 
> : {{ page.date | date: '%A, %B %-d' }}, 15:00--16:00 (MontrÃ©al time, UTC-5)
>
> __Where:__  
> : MCQLL meetings this semester are in hybrid format.  We will meet in-person
> in room 117 of the McGill Linguistics Department, [1085
> Dr-Penfield](https://maps.mcgill.ca/?cmp=1&txt=EN&id=Penfield1085). If you'd
> like to attend virtually, the Zoom link is
> [here](https://mcgill.zoom.us/j/85321158610).


All are welcome to attend.

-  __Speaker:__
    : Eva Portelance

    __Title:__
    : The roles of neural networks in language acquisition

    __Abstract:__ 
    : > How can modern neural networks like large language models be useful to the field of language acquisition, and more broadly cognitive science, if they are not a priori designed to be cognitive models? As developments towards natural language understanding and generation have improved leaps and bounds, with models like GPT-4, the question of how they can inform our understanding of human language acquisition has re-emerged. As such, it is critical to examine how in practice linking hypotheses between models and human learners can be safely established. To address these questions, I present a model taxonomy, including four modeling approaches, each having differing goals, from exploratory hypothesis generation to hypothesis differentiation and testing. I ground each approach in the realist vs. instrumentalist debates in philosophy of science and present in practice examples of two of these approaches from my own work.

