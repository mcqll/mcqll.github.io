---
layout: post
title: Lab meeting - Jasper Jian and Massimo Lipari
date: 2022-11-15
published: true
inline: false
---

At this week's MCQLL meeting, we have two speakers. **Jasper Jian** will give a talk titled _Unsupervised Induction of Syntactic Structure from Neural Language Models_ and **Massimo Lipari** will give a talk titled _Rhotic Vowels in Quebec French_.

__When:__ 
: {{ page.date | date: '%A, %B %-d' }}, 15h00--16h00 (MontrÃ©al time, UTC-4)

__Where:__  
: MCQLL meetings this semester are in hybrid format.  We will meet in-person in room 117 of the McGill Linguistics Department, [1085 Dr-Penfield](https://maps.mcgill.ca/?cmp=1&txt=EN&id=Penfield1085). If you'd like to attend virtually, Zoom meetings will be held [here](https://mcgill.zoom.us/j/84089215248?pwd=UkpMK1FEV2dTaVpGSDMzLzJtNWFhUT09).

All are welcome to attend.


-  __Speaker:__
    : Jasper Jian.

    __Title:__
    : Unsupervised Induction of Syntactic Structure from Neural Language Models

    __Abstract:__
    : > In recent years, large pretrained language models (LLMs) have led to impressive performance gains across a wide range of NLP tasks. This has led to questions about how exactly Natural Language Understanding occurs within these models, and what sorts of linguistic phenomena are captured. One such property, which we investigate here, is syntax. Previous work has shown that LLMs not only perform well on syntax-dependent tasks, but that tree-like representations can be extracted from model-internal mechanisms. In this work we expand on this last point and develop an unsupervised method to constrain and extract syntactic structures from LLMs. We aim to gain a better understanding of model-intrinsic syntax, peeking inside the black-box of modern LLMs, as well as develop a strategy which makes use of LLMs to investigate linguistic theory. 

-  __Speaker:__
    : Massimo Lipari

    __Title:__
    : Rhotic Vowels in Quebec French
